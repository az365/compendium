# Математика

<a name="stat"></a>
## Матстат

### Intro
- probability theory, statistics - тервер, матстат
  - [Виды распределений и их моменты](./math.md#distr)
  - [Описательная статистика](./math.md#descriptive)
  - [Статистический вывод](./math.md#induct)
  - [Статистические модели](./math.md#models)
  - [Кластеризация](./ds.md#clustering)
- статистические типы данных
  - качественные (категориальные): номинальные, порядковые
  - количественные (числовые): дискретные, непрерывные

<a name="distr"></a>
### Виды распределений и их моменты
- `U[a;b]` равномерное
- `N(mu, sigma2)` нормальное = Гауссовский шум
  - плотность вероятности: `f(x) = 1/sqrt(2*pi) * e^-((x-mu)^2/2*sigma^2)`
  - моменты ...
  - свойства
    - ЦПТ: сумма случайных событий, семплированных из любого типа слабо зависимых распределений, сама является случайной величиной и в пределе распределена нормально
    - бесконечная делимость
    - максимальная энтропия
    - правило трёх сигм
  - применения
    - отклонения при стрельбе
    - погрешность измерений
    - некоторые характеристики живых организмов в популяции
  - связь с другими распределениями
    - частный случай распределения
    - ЦПТ: сумма одинаково распределённых величин
  - тесты на нормальность распределения
    - Критерий Шапиро-Уилка
      - Критерий хи-квадрат
      - Критерий Колмогорова-Смирнова
- `LogN(mu, sigma2)` - логнормальное
- `Exp(lambda)` показательное = экспоненциальное
  - моделирует время между двумя последовательными свершениями одного и того же события
- `Be(p)` Бернулли
  - дискретное распределение вероятностей
  - моделирует случайный эксперимент, при заранее известной вероятности успеха или неудачи
  - параметры 
    - `p` - вероятность успеха
  - моменты распределения
    - `E[X] = P`
    - `D[X] = pq = p*(1-p)`
    - `E[X^n] = p`
  - связь с другими распределениями
    - Y=sum(Xi) имеет биномиальное распределение: Y ~ Bin(n,p)
  - применения
    - монетка
    - дисперсия доли
    - анкетирование, контроль качества, ...
- `Bi(n,p)` биномиальное
  - распределение количества успехов в n экспериментах (в которых вероятность успеха равна p)
  - функция вероятности: `pY(k) = P(Y=k) = (nk) * p^k * q^n-k` 
    - биномиальный коэффициент: `(nk) = n!/(n-k)!*k!`
  - функция распределения: `FY(y) = P(Y<=y) = sum k=0..y ((nk) * p^k * q^n-k )`
  - моменты распределения
    - `E[Y] = np`
    - `E[Y2] = np(q+np)`
    - `D[Y] = npq`
  - связь с другими распределениями
    - `n=1 -> Bi(1,p) ~ Be(p)` распределение бернулли
    - `n=100500 -> Bin(100500,p) ~ N(np,npq)` - нормальное распределение
    - `n=100500, lambda=const -> Bin(n,lambda/n) ~ P(lambda)` - распределение Пуассона
  - применения
    - количество орлов
- `Pois(lambda)` - распределение Пуассона
  - моделирует число событий за фиксированное время
    - события происходят с некоторой фиксированной средней интенсивностью и независимо друг от друга
  - параметры
    - `lambda` - матожидание, среднее количество событий за фиксированный промежуток времени
  - функция вероятности: `p(k) = P(Y=k) = lambda^k/k! * e^-lambda`
  - моменты
    - `E[Y] = lambda`
    - `D[Y] = lambda`
  - применение
    - теория массового обслуживания
- `t(m)` - t-распределение Стьюдента
  - насколько вероятно, что истинное среднее находится в каком-либо заданном диапазоне
  - частный случай обобщённого гиперболического распределения
  - определение
    - случайная величина (имеющая распределение Стьюдента): `t = Y0/sqrt(1/m * sum i=1..n Yi^2)`
    - `Y0..m` - независимые стандартные нормальные случайные: `Yi ~ N(0,1)`
  - параметры
    - `m` - степени свободы
  - применение
    - статистический анализ
      - t-критерий оценки разницы между 2 выборочными средними
      - построение доверительных интервалов разницы 2 доверительных средних
      - линейная регрессия
      - байесовский анализ данных, распределённых по нормальному закону
- `F(m,n)` - F-распределение Фишера
- `хи2(m)` - хи-квадрат
  - распределение суммы квадратов k независимых стандартных нормальных случайных величин.
  - параметры
    - m - степени свободы
  - связи
    - выборочная дисперсия нормального распределения имеет распределение хи-квадрат

<a name="descriptive"></a>
### Описательная статистика
- дескриптивная статистика = описательная статистика = меры среднего уровня и рассеяния
  - обработка и описание эмпирических данных
- моменты
  - определения
    - kй начальный момент: `nu k = E(X^k)`
    - kй центральный момент: `mu k = E[(X-E(X))^k]`
  - геометрический смысл
    - 1 матожидание
    - 2 дисперсия
    - 3 асимметрия
    - 4 эксцесс
- меры среднего
  - среднее арифметическое, геометрическое, гармоническое
  - матожидание / Expected value
    - среднее при стремлении числа измерений к бесконечности
      - при конечном числе измерений - имеем оценку матожидания
    - обозначения: `E[X], M[X], mu`
    - формулы
      - определение: `E[X] = int Omega: X(omega)*P(d omega)`
      - `E[X] = int -inf,inf x dFx(x)`
        - `Fx(x)` - функция распределения
      - матожидание дискретного распределения: ...
      - матожидание целочисленной величины: ...
      - матожидание непрерывного распределения: ...
  - медиана
  - мода 
  - квантиль
  - асимметрия / Scewness
    - коэффициент `gamma = mu3 / sigma3`
    - как выглядит
      - positive skew - распределение наклонено влево
      - negative skew - распределение наклонено вправо
  - эксцесс
    - мера остроты пика распределения
    - формула: `mu4 = E[(X - EX)^4]`
    - коэффициент эксцесса
      - `gamma2 = mu4 / sigma^4 - 3`
      - минус 3 здесь - чтобы экцесс нормального распределения был равен нулю
      - положителен, если пик распределения острый
      - отрицателен, если пик очень гладкий
  - интервал 
    - пара чисел, между которыми предположительно находится оцениваемый параметр
  - доверительный интервал
    - покрывает неизвестный параметр с заданной надёжностью p
- меры рассеяния
  - дисперсия `DL, D[X], Var(X)`
    - `D[x] = E[(X - E(X))^2]`
    - `D[X] = sigma^2`
    - вероятность, что значения случайной отстоят от матожидания более чем на k СКО, - менее `1 / k^2`
  - стандартное отклонение = срендеквадратическое отклонение СКО, `sigma`
    - `sigma = sqrt(D[X])`
  - стандартаная ошибка SD
    - `SD = sigma / sqrt(n)`
  - размах вариации
  - интерквантильный размах

<a name="induct"></a>
### Статистический вывод
- индуктивная статистика = статистический вывод = statistical inference = inductive statistics
  - обобщение информации из выборки для получения представления о свойствах генеральной совокупности
  - антоним: дескриптивная статистика
- результат инференса - статистическое суждение
  - точечная оценка
  - доверительный интервал
  - проверка (отвержение) гипотезы
  - кластерный анализ
- школы: частотный и байесовский вывод
  - частотныцй вывод
    - natural frequencies – частоты, которые не были нормализованы относительно базовых показателей рассматриваемого события
  - байесовский вывод
    - `p(X|Y) = p(Y|X)*p(X)/p(Y)`
  - информация и вычислительная сложность
- разделы
  - проверка стат-гипотез
    - Статистическая гипотеза — предположение о виде распределения и свойствах случайной величины, которое можно подтвердить или опровергнуть применением статистических методов к данным выборки
    - алгоритм проверки стат-гипотез
      - формулировка нулевой гипотезы
      - задание уровня значимости
      - выбор статистики
      - выбор критической области
      - вычисление статистики и решение о принятии гипотезы
    - критерии
      - параметрические
        - t-критерий Стьюдента
          - основан на распределении Стьюдента
          - для проверки равенства средних в 2 выборках с нормальным распределением и равных дисперсиях
          - одновыборочный t-критерий
            - `t = (X-m) / SX/sqrt(n)`
          - двухвыборочный t-критерий для независимых выборок
          - двухвыборочный t-критерий для зависимых выборок
            - `t = Md / Sd/sqrt(n)`
              - `Md` - средняя разность значений
              - `Sd` - СтОткл разностей
          - при превышении abs(t) критического значения (при заданном уровне значимости) нулевая гипотеза (H0: E(X)=m) отвергается
        - Z-критерий Фишера
          - основан на нормальном распределении
          - для проверки равенства средних значений при известной дисперсии генеральной совокупности
          - `z = (X - m) / SE` 
            - `X` - выборочное среднее
            - `m` - матожидание
            - `SE = sigma / sqrt(n)`, `sigma` - СКО
          - z критическое
            - при уровне значимости 5%: `z < −1.96` или `z > 1.96`
        - F-критерий Фишера
          - `F = W/q` (если при расчёте статистики Вальда использовалась несмещённая оценка дисперсии)
          - `F = (n-k)/q * W/n`
        - LR - критерий отношений правдоподобия
          - `LM = LR = W`: тест Вальда (W), тест отношения правдоподобия (LR) и тест множителей Лагранжа (LM) — асимптотически эквивалентные тесты
      - непараметрические
        - U-test Манна-Уитни
          - достаточно ли мала зона перекрещивающихся значений между двумя вариационными рядами
          - посчитать суммы раннгов n1, n2
          - `U = n1*n2 + nx*(nx + 1)/2 - Tx`
            - `n1`, `n2` - количества элементов в выборках
            - `Tx` - большая из двух ранговых сумм
            - `nx` - число элементов в выборке с бОольшей ранговой суммой
          - если U меньше табличного - признается наличие существенного различия между признаком в выборках
        - критерий Уилкоксона
        - критерий Пирсона
        - ...
    - `video` [YouTube: Data Mining in Action. Проверка статистических гипотез и A/B тестирование](https://www.youtube.com/watch?v=YULMqwo7Tas)
  - выборочное обследование
    - определение свойств генеральной совокупности на основании стат-исследования выборки
  - теория оценивания
    - Статистические оценки — это статистики, которые используются для оценивания неизвестных параметров распределений случайной величины
    - оценка: точечная vs интервальная
    - свойства точечной оценки
      - состоятельная - при увеличении числа опытов оценка Theta сходится по вероятности к параметру Theta
      - несмещённая - если математическое ожидание оценки совпадает с оцениваемым параметром: E[Theta]=Theta
        - примеры
          - выборочное среднее - несмещённая оценка матожидания
          - исправленная выборочная дисперсия (делённая на n-1 вместо n) - несмещённая оценка дисперсии
      - эффективная - если дисперсия несмещённой оценки является минимальной по сравнению с другими оценками
    - ... 
  - теория принятия решений

<a name="models"></a>
### Статистические модели
- оценка параметров моделей производится с помощью статистических методов
  - метод максимального правдоподобия
    - вероятность vs правдоподобие
      - вероятность предсказывает неизвестные результаты по известным параметрам
      - правдоподобие оценивает неизвестные параметры по известным результатам
    - логарифмическая функция правдоподобия: L(X|teta) = ln fX(X|teta) = sum i=1..n (ln fX(xi|teta))
  - метод наименьших квадратов
  - метод моментов
- виды статистических и эконометрических моделей
  - Линейная (OLS)
  - Авторегрессионная модель
  - Система одновременных уравнений (SEM)
  - Модель линейной вероятности (LPM)
  - Логит модель (Logit)
    - прогнозирует вероятность события по значениям множества признаков
    - путём подгонки данных к логистической кривой
    - дифур: `dP/dt = tau P*(1-P/K)`
      - `P` - популяция
      - `t` - время
      - `K` - ёмкость среды
    - логистическая кривая: `P(t) = K P0 e^(tau*t) / (K + P0 (e^(tau*t) - 1))`
    - сигмоида = логит-функция: `1 / (1+e^-z)`
    - функция распределения - Бернулли: `P{y|x} = p^y * (1-p)^(1-y)`, где параметр `p = f(teta^T * x)`
  - Пробит модель (Probit)
    - probit = probability unit
    - основана на нормальном распределении
    - частный случай модели бинарного выбора
    - probit-функция
      - обратна к интегральной функции (CDF) стандартного нормального распределения
      - определяет квантиль стандартного нормального распределения для заданной вероятности x q = Ф^−1(q)
    - пробит-модель: `p(x) = P(Y=1|X=x) = Ф(x^T*b)`
      - Ф - интегральная функция распределения (CDF) стандартного нормального распределения
      - b - неизвестные параметры, которые требуется оценить
    - оценка качества пробит-регрессии (или любой модели бинарного выбора)
      - статистика отношения правдоподобия LR
      - псевдо-коэффициент детерминации R2pseudo
      - коэффициент детерминации МакФаддена (индекс отношения правдоподобия) R2mcfadden, LRI 
      - информационные критерии Акаике, Шварца, Ханнана-Куинна AIC, BIC(SC), HQ
      - ...

<a name="clustering"></a>
### Кластерный анализ
- [ds.md#clustering](./ds.md#clustering)

<a name="linalg"></a>
## Линейная алгебра

### Основные конструкции
- скаляр
- вектор
  - vector space = векторное пространство
    - евклидово пространство - частный случай векторного пространства размерности 3
  - векторное исчисление 
    - векторная алгебра
      - сложение, умножение векторов на число 
      - произведения векторов: скалярное (внутреннее), псевдоскалярное, векторное (внешнее), смешанное, двойное векторное, ...
      - аналитическая геометрия - геометрические свойства: коллинеарность, компланарность векторов, свойства векторного базиса
      - тензорная алгебра - расширение векторной алгебры: алгебраические операции над тензорами 
    - векторный анализ
      - исследует
        - статические/стационарные/динамические векторные/скалярные поля
        - взаимоотношения определяющих поля скаляров и векторов
      - понятия векторного анализа
        - поток вектора: поток векторного поля через поверхность, фазовый поток — поток векторного поля A→
        - циркуляция вектора (векторного поля): аддитивность, формула Стокса
        - градиент - направление и скорость возрастания скалярной величины φ (скалярное поле)
      - тензорный анализ - расширение векторного анализа: дифференциальные операторы на алгебре `D(M)`
    - функциональный анализ
      - разделы функцонального анализа
        - теория меры и интеграла
        - теория функций
        - теория операторов
        - дифференциальное исчисление на бесконечномерных пространствах
      - применения 
        - теория дифференциальных уравнений
        - математическая физика
        - теоретическая физика (квантовая механика, теория струн)
        - теория управления и оптимизации
        - теория вероятностей
        - математическая статистика
        - теория случайных процессов
        - теория преобразования Фурье (используется в обработке изображений)
      - понятия 
        - мера, метрика, норма, скалярное произведение
          - мера - числовая функция, ставящая в соответствие каждому множеству некоторое неотрицательное число
          - метрика - функция на парах элементов множества, вводящая на нём расстояние 
          - норма - функционал на векторном пространстве, обобщает понятие длины вектора (абсолютного значения числа)
        - оператор, функционал (для отображений пространств)
          - оператор - отображение между множествами, где каждое наделено дополнительной структурой (порядком, топологией, алгебраическими операциями)
          - функционал 
            - функция, заданная на произвольном множестве и имеющая числовую область значений (чисел)
            - отображение из произвольного множества в произвольное (не обязательно числовое) кольцо
        - пространства непрерывных функций
        - пространства интегрируемых функций
- матрица и определитель
  - ранг (столбцовый/строчный) - число линейно независимых столбцов/строк
  - область значений и нуль-пространство (согласно [Otus: Линейная алгебра для исследователей данных @ Habr](https://habr.com/ru/company/otus/blog/562744))
    - `span({x1...xn})` = линейная оболочка (векторов `{x1...xn}`) - множество всех векторов, которые могут быть представлены линейной комбинацией векторов `{x1...xn}`
    - область значений `R(A)` = пространством столбцов матрицы `A` - линейная оболочка её столбцов
    - `kerA` = `N(A)` = ядро матрицы = нуль-пространство - множество всех векторов, которые при умножении на `A` обращаются в нуль
  - что надо знать DS про матрицы (согласно [SkillFactory: Линейная алгебра для DS и ML @ Habr](https://habr.com/ru/company/skillfactory/blog/556954))
    - транспонирование матрицы 
    - обратная матрица
    - определитель матрицы
    - след матрицы - сумма элементов на ее главной диагонали
    - скалярное произведение
    - собственные значения
    - собственные векторы
- тензор
  - тензорное исчисление - расширение векторного исчисления
    - тензорная алгебра - расширение векторной алгебры: алгебраические операции над тензорами
      - тензорный анализ - расширение векторного анализа: дифференциальные операторы на алгебре `D(M)`
        - matrix and tensor derivatives = производные матриц и векторов
          - `course` [coursera: Intro to DeepLearning - Matrix Derivatives](https://www.coursera.org/learn/intro-to-deep-learning/lecture/YTunl/other-matrix-derivatives)
          - `pdf` `article` [github: Erik Learned-Miller - Vector, Matrix, and Tensor Derivatives](https://compsci697l.github.io/docs/vecDerivs.pdf)
          - `pdf` `book` [matrixcookbook.com: The Matrix CookBook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)

### Применения
- Решение систем линейных алгебраических уравнений
- Теория представлений
- Линейное программирование
- Эконометрика
- Квантовая механика

### Литература
- `post` [SkillFactory: Линейная алгебра для DS и ML @ Habr](https://habr.com/ru/company/skillfactory/blog/556954)
- `post` [Otus: Линейная алгебра для исследователей данных @ Habr](https://habr.com/ru/company/otus/blog/562744)
- `course` [coursera: Intro to DeepLearning - Matrix Derivatives](https://www.coursera.org/learn/intro-to-deep-learning/lecture/YTunl/other-matrix-derivatives)
- `pdf` `article` [github: Erik Learned-Miller - Vector, Matrix, and Tensor Derivatives](https://compsci697l.github.io/docs/vecDerivs.pdf)
- `pdf` `book` [matrixcookbook.com: The Matrix CookBook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)

<a name="discrete"></a>
## Дискретная математика
- разделы
  - теория функциональных систем
  - теория графов
  - теория автоматов
  - теория кодирования
  - комбинаторика
  - целочисленное программирование
- курсы
  - `course` coursera: Дискретная математика для компьютерных наук - Михаил Левин

<a name="numeric"></a>
## Численные методы
- интерполирование и приближённое вычисление функций
  - интерполяция
  - равномерные приближения
  - среднеквадратичные приближения
- численное дифференцирование и интегрирование 
- решение систем уравнений
  - решение систем линейных уравнений
  - решение системы нелинейных уравнений
  - решение обыкновенных дифференциальных уравнений
  - решение уравнений в частных производных (уравнений математической физики)
- оптимизация = математическое программирование
  - определения
    - математическое программирование изучает теорию и методы решения задачи оптимизации
    - `lecture` `pdf` [С.Владимиров - Теория принятия решений: Численные методы оптимизации](http://opds.spbsut.ru/data/_uploaded/mu/tpr/vlsa-present/tpr_05_chisl_met_optim.pdf)
      - поиск лучшего из возможных вариантов
    - `wiki` [Оптимизация](https://ru.wikipedia.org/wiki/https://ru.wikipedia.org/wiki/Оптимизация)
      - процесс максимизации выгодных характеристик, соотношений (например, оптимизация производственных процессов и производства), и минимизации расходов.
    - `wiki` [Оптимизация (в математике, информатике и исследовании операций)](https://ru.wikipedia.org/wiki/Оптимизация_(математика)) 
      - нахождение экстремума целевой функции, ограниченной набором уравнений/неравенств
      - это область математики, разрабатывающая теорию, численные методы решения многомерных задач с ограничениями
  - структура и постановка задач оптимизации (согласно [С.Владимирову](http://opds.spbsut.ru/data/_uploaded/mu/tpr/vlsa-present/tpr_05_chisl_met_optim.pdf))
    - словесное представление о параметрах задачи, множестве ее решений и поставленной цели
      - параметры задачи `xi, (i=1,2,...,n)` - это переменные, значения которых необходимо определить в результате ее решения
    - запись критерия оптимальности (целевой функции) как функции параметров задачи
      - критерий оптимальности представляют в виде целевой функции `f(X), X=(x1, x2, … , xn)` или функционала `I(X)` времени или координаты
    - запись условий, определяющих область допустимых значений параметров `xi , (i=1,2,…,n)`
      - определяется неравенствами `gj(X)≤0; (j=1,2,...,m)` или связями (равенствами) `hk(X)=0; (k=1,2,...,p)`
  - классификации задач
    - согласно [Википедии](https://ru.wikipedia.org/wiki/Оптимизация_(математика))
      - условная/безусловная
      - локальная/глобальная
      - детерминированные/случайные/комбинированные
      - размерность: одномерная, многомерная оптимизация
      - вид целевой функции: линейное, нелинейное (выпуклое, целочисленное=дискретное) программирование
      - по гладкости и наличию частных производных: прямые методы, первого, второго порядка (про гессиан)
      - методы: аналитические (множетели Лагранджа, условия Каруша-Куна-Такера), численные, графические
      - задачи математического программирования
        - в зависимости от природы множества X 
          - задачи дискретного программирования (или комбинаторной оптимизации) - если X конечно или счётно
          - задачи целочисленного программирования - если X подмножество целых
          - задачи нелинейного программирования - если ограничения или целевая функция содержат нелинейные функции
          - задача линейного программирования - если все ограничения и целевая функция содержат лишь линейные функции
        - прочие 
          - параметрическое программирование
          - динамическое программирование - способ решения сложных задач путём разбиения их на более простые подзадачи
          - стохастическое программирование - прикладные задачи обычно содержат некоторые неизвестные параметры
    - согласно [Habr: Обзор методов численной оптимизации](https://habr.com/ru/post/561128)
      - условная/безусловная
      - локальная/глобальная
      - по трудоёмкости целевой функции
        - тяжёлые - вычисление функции дороже, чем вычисление оптимизации, желательно реже вызывать целевую функцию
        - лёгкие - вычисление функции дёшево, но параметров много, поэтому вычисление оптимизации дороже
        - шумные - когда целевая функции вычислется неточно
      - по гладкости и наличию частных производных: прямые методы, первого, второго порядка (про гессиан)
        - методы, использующие производную
        - безградиентныме (derivative-free) методы
    - согласно [С.Владимирову](http://opds.spbsut.ru/data/_uploaded/mu/tpr/vlsa-present/tpr_05_chisl_met_optim.pdf)
      - наличие или отсутствие ограничений и связей: безусловный экстремум, условный экстремум
      - вид критерия оптимальности: вариационные задачи (критерий — функционал), задачи математического программирования (критерий - функция)
      - характер функций `f, g, h`: (не)линейное программирование (хотя бы одна из функций - нелинейная)
      - характер параметров: непрерывные значения, дискретное (целочисленное) программирование, комбинаторная задача (если число значений конечно)
  - применения (согласно [УрФУ - Теория принятия решений (1994)](http://hdl.handle.net/10995/27717))
    - применения линейного программирования
      - Оптимальное использование ресурсов
      - Планирование инвестиций
      - Транспортная задача
      - Задача о назначениях
      - Задача коммивояжёра (решается линейным или динамическим программированием)
    - применение нелинейного и квадратичного программирования
      - Выбор инвестиционного портфеля (задача Марковица)
    - применения динамического программирования
      - Распределение ресурсов
      - Задача о замене оборудования
      - Управление конечным состоянием (задача Майера)
      - Задача коммивояжёра (решается линейным или динамическим программированием)
      - Управляемые марковские процессы
  - процедуры 
    - 5 типов вычислительных процедур оптимизации [С.Владимирову](http://opds.spbsut.ru/data/_uploaded/mu/tpr/vlsa-present/tpr_05_chisl_met_optim.pdf)
      - Сравнение значений целевой функции на сетке значений аргументов (аналог в дискретном программировании - полный/локальный перебор)
      - Использование необходимых условий экстремума (применение ограничено, т.к. не всегда есть выражения производных)
      - Использование достаточных условий оптимальности (вспомогательная задача, например, безусловная оптимизация вместо условной)
      - Отсечение множеств заведомо неоптимальных решений (метод золотого сечения, ветвей и границ для экстремальных комбинаторных задач)
      - Построение оптимизирующей последовательности допустимых решений (большинство методов оптимизации основаны именно на этой процедуре)
  - методы
    - характеристики методов (согласно [Habr: Обзор методов численной оптимизации](https://habr.com/ru/post/561128))
      - Глобальная сходимость - сходятся ли итерации к локальному(!) минимуму независимо от начального положения
      - Скорость локальной сходимости - насколько быстро метод настигает минимизатор, когда он уже близко
      - Размеры задачи - объём памяти для матриц растёт квадратично с увеличением размера задачи
      - Требуется ли хранить в памяти матрицы или нет
      - Требуется ли матрица Гессе или нет
      - Требуется ли масштабирование или нет
    - список методов
      - метод линий
        - одномерная минимизация
          - метод золотого сечения
          - пошаговый метод
        - многомерная оптимизация - для функций многих переменных
          - метод Гаусса-Зайделя (замена многопараметрической задачи последовательностью однопараметрических задач поиска частных экстремумов)
          - метод наискорейшего спуска
            - градиентный метод
          - методы случайного поиска
        - метод Ньютона
        - методы квази-Ньютона
        - Приглушённый BFGS
        - Метод нелинейных сопряжённых градиентов (NCG)
        - Усечённый метод Ньютона (truncated Newton method)
        - BFGS c ограниченной памятью
      - более редкие методы
        - Mixed-Integer Programming рассматривает дискретные сценарии
        - недетерминированная (хаотическая) оптимизация использует вероятностные подходы
        - робастная оптимизация - заложены параметры, не являющиеся переменными
        - оптимизация динамических систем - присутствует эволюция во времени
        - мета-эвристические методы: метод имитируемого отжига (simulated annealing), генетические алгоритмы, методы эволюции роя
        - оптимизация неопределённой логики (fuzzy logic optimization)
  - Литература
    - `post` [Habr: Обзор методов численной оптимизации. Безусловная оптимизация: метод линий](https://habr.com/ru/post/561128)
    - `lecture` [С.Владимиров - Теория принятия решений: Численные методы оптимизации](http://opds.spbsut.ru/data/_uploaded/mu/tpr/vlsa-present/tpr_05_chisl_met_optim.pdf)
    - `lecture` [УрФУ - Теория принятия решений (1994)](http://hdl.handle.net/10995/27717)
