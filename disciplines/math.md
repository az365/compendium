math
	- probability theory, statistics - тервер, матстат
		- виды распределений и их моменты
			- U[a;b] равномерное
			- N(mu, sigma2) нормальное = Гауссовский шум
				- плотность вероятности: f(x) = 1/sqrt(2*pi) * e^-((x-mu)^2/2*sigma^2)
				- моменты ...
				- свойства
					- ЦПТ: сумма случайных событий, семплированных из любого типа слабо зависимых распределений, сама является случайной величиной и в пределе распределена нормально
					- бесконечная делимость
					- максимальная энтропия
					- правило трёх сигм
				- применения
					- отклонения при стрельбе
					- погрешность измерений
					- некоторые характеристики живых организмов в популяции
				- связь с другими распределениями
					- частный случай распределения пирсона
					- ЦПТ: сумма одинаково распределённых величин
			- LogN(mu, sigma2) - логнормальное
			- Exp(lambda) показательное = экспоненциальное
				- моделирует время между двумя последовательными свершениями одного и того же события
			- Be(p) Бернулли
				- дискретное распределение вероятностей
				- моделирует случайный эксперимент, при заранее известной вероятности успеха или неудачи
				- параметры 
					- p - вероятность успеха
				- моменты распределения
					- E[X] = P
					- D[X] = pq = p*(1-p)
					- E[X^n] = p
				- связь с другими распределениями
					- Y=sum(Xi) имеет биномиальное распределение: Y ~ Bin(n,p)
				- применения
					- монетка
					- дисперсия доли
					- анкетирование, контроль качества, ...
			- Bi(n,p) биномиальное
				- распределение количества успехов в n экспериментах (в которых вероятность успеха равна p)
				- функция вероятности: pY(k) = P(Y=k) = (nk) * p^k * q^n-k 
					- биномиальный коэффициент: (nk) = n!/(n-k)!*k!
				- функция распределения: FY(y) = P(Y<=y) = sum k=0..y ((nk) * p^k * q^n-k )
				- моменты распределения
					- E[Y] = np
					- E[Y2] = np(q+np)
					- D[Y] = npq
				- связь с другими распределениями
					- n=1 -> Bi(1,p) ~ Be(p) распределение бернулли
					- n=100500 -> Bin(100500,p) ~ N(np,npq) - нормальное распределение
					- n=100500, lambda=const -> Bin(n,lambda/n) ~ P(lambda) - распределение Пуассона
				- применения
					- количество орлов
			- Pois(lambda) - распределение Пуассона
				- моделирует число событий за фиксированное время
					- события происходят с некоторой фиксированной средней интенсивностью и независимо друг от друга
				- параметры
					- lambda - матожидание, среднее количество событий за фиксированный промежуток времени
				- функция вероятности: p(k) = P(Y=k) = lambda^k/k! * e^-lambda
				- моменты
					- E[Y] = lambda
					- D[Y] = lambda
				- применение
					- теория массового обслуживания
			- t(m) - t-распределение Стьюдента
				- насколько вероятно, что истинное среднее находится в каком-либо заданном диапазоне
				- частный случай обобщённого гиперболического распределения
				- определение
					- случайная величина (имеющая распределение Стьюдента): t = Y0/sqrt(1/m * sum i=1..n Yi^2)
					- Y0..m - независимые стандартные нормальные случайные: Yi ~ N(0,1)
				- параметры
					- m - степени свободы
				- применение
					- статистический анализ
						- t-критерий оценки разницы между 2 выборочными средними
						- построение доверительных интервалов разницы 2 доверительных средних
						- линейная регрессия
						- байесовский анализ данных, распределённых по нормальному закону
			- F(m,n) - F-распределение Фишера
			- хи2(m) - хи-квадрат
				- распределение суммы квадратов k независимых стандартных нормальных случайных величин.
				- параметры
					- m - степени свободы
				- связи
					- выборочная дисперсия нормального распределения имеет распределение хи-квадрат
		- дескриптивная статистика = описательная статистика = меры среднего уровня и рассеяния
			- обработка и описание эмпирических данных
			- моменты
				- определения
					- kй начальный момент: nu k = E(X^k)
					- kй центральный момент: mu k = E[(X-E(X))^k]
				- геометрический смысл
					1 матожидание
					2 дисперсия
					3 асимметрия
					4 эксцесс
			- меры среднего
				- среднее арифметическое, геометрическое, гармоническое
				- матожидание / Expected value
					- среднее при стремлении числа измерений к бесконечности
						- при конечном числе измерений - имеем оценку матожидания
					- обозначения: E[X], M[X], mu
					- формулы
						- определение: E[X] = int Omega: X(omega)*P(d omega)
						- E[X] = int -inf,inf x dFx(x)
							- Fx(x) - функция распределения
						- матожидание дискретного распределения: ...
						- матожидание целочисленной величины: ...
						- матожидание непрерывного распределения: ...
				- медиана
				- мода 
				- квантиль
				- асимметрия / Scewness
					- коэффициент gamma = mu3 / sigma3
					- как выглядит
						- positive skew - распределение наклонено влево
						- negative skew - распределение наклонено вправо
				- эксцесс
					- мера остроты пика распределения
					- формула: mu4 = E[(X - EX)^4]
					- коэффициент эксцесса
						- gamma2 = mu4 / sigma^4 - 3
						- минус 3 здесь - чтобы экцесс нормального распределения был равен нулю
						- положителен, если пик распределения острый
						- отрицателен, если пик очень гладкий
				- интервал 
					- пара чисел, между которыми предположительно находится оцениваемый параметр
				- доверительный интервал
					- покрывает неизвестный параметр с заданной надёжностью p
			- меры рассеяния
				- дисперсия DL, D[X], Var(X)
					- D[x] = E[(X - E(X))^2]
					- D[X] = sigma^2
					- вероятность, что значения случайной отстоят от матожидания более чем на k СКО, - менее 1 / k^2
				- стандартное отклонение = срендеквадратическое отклонение СКО, sigma
					- sigma = sqrt(D[X])
				- стандартаная ошибка SD
					- SD = sigma / sqrt(n)
				- размах вариации
				- интерквантильный размах
		- индуктивная статистика = статистический вывод = statistical inference = inductive statistics
			- обобщение информации из выборки для получения представления о свойствах генеральной совокупности
			- антоним: дескриптивная статистика
			- результат инференса - статистическое суждение
				- точечная оценка
				- доверительный интервал
				- проверка (отвержение) гипотезы
				- кластерный анализ
			- школы: частотный и байесовский вывод
				- частотныцй вывод
					- natural frequencies) – частоты, которые не были нормализованы относительно базовых показателей рассматриваемого события
				- байесовский вывод
					- p(X|Y) = p(Y|X)*p(X)/p(Y)
				- информация и вычислительная сложность
			- разделы
				- проверка стат-гипотез
					- Статистическая гипотеза — предположение о виде распределения и свойствах случайной величины, которое можно подтвердить или опровергнуть применением статистических методов к данным выборки
					- алгоритм проверки стат-гипотез
						- формулировка нулевой гипотезы
						- задание уровня значимости
						- выбор статистики
						- выбор критической области
						- вычисление статистики и решение о принятии гипотезы
					- критерии
						- параметрические
							- t-критерий Стьюдента
								- основан на распределении Стьюдента
								- для проверки равенства средних в 2 выборках с нормальным распределением и равных дисперсиях
								- одновыборочный t-критерий
									- t = (X-m) / SX/sqrt(n)
								- двухвыборочный t-критерий для независимых выборок
								- двухвыборочный t-критерий для зависимых выборок
									- t = Md / Sd/sqrt(n)
										- Md - средняя разность значений
										- Sd - СтОткл разностей
								- при превышении abs(t) критического значения (при заданном уровне значимости) нулевая гипотеза (H0: E(X)=m) отвергается
							- Z-критерий Фишера
								- основан на нормальном распределении
								- для проверки равенства средних значений при известной дисперсии генеральной совокупности
								- z = (X - m) / SE 
									- X - выборочное среднее
									- m - матожидание
									- SE = sigma / sqrt(n), sigma - СКО
								- z критическое
									- при уровне значимости 5%: z < −1.96 или z > 1.96
							- F-критерий Фишера
								- F = W/q (если при расчёте статистики Вальда использовалась несмещённая оценка дисперсии)
								- F = (n-k)/q * W/n
							- LR - критерий отношений правдоподобия
								- LM = LR = W: тест Вальда (W), тест отношения правдоподобия (LR) и тест множителей Лагранжа (LM) — асимптотически эквивалентные тесты
						- непараметрические
							- U-test Манна-Уитни
								- достаточно ли мала зона перекрещивающихся значений между двумя вариационными рядами
								- посчитать суммы раннгов n1, n2
								- U = n1*n2 + nx*(nx + 1)/2 - Tx
									- n1, n2 - количества элементов в выборках
									- Tx - большая из двух ранговых сумм
									- nx - число элементов в выборке с бОольшей ранговой суммой
								- если U меньше табличного - признается наличие существенного различия между признаком в выборках
							- критерий Уилкоксона
							- критерий Пирсона
							- ...
					- Data Mining in Action / Проверка статистических гипотез и A/B тестирование https://www.youtube.com/watch?v=YULMqwo7Tas
				- выборочное обследование
					- определение свойств генеральной совокупности на основании стат-исследования выборки
				- теория оценивания
					- Статистические оценки — это статистики, которые используются для оценивания неизвестных параметров распределений случайной величины
					- оценка: точечная vs интервальная
					- свойства точечной оценки
						- состоятельная - при увеличении числа опытов оценка Theta сходится по вероятности к параметру Theta
						- несмещённая - если математическое ожидание оценки совпадает с оцениваемым параметром: E[Theta]=Theta
							- примеры
								- выборочное среднее - несмещённая оценка матожидания
								- исправленная выборочная дисперсия (делённая на n-1 вместо n) - несмещённая оценка дисперсии
						- эффективная - если дисперсия несмещённой оценки является минимальной по сравнению с другими оценками
					- 
				- теория принятия решений
		- статистические модели
			- оценка параметров моделей производится с помощью статистических методов
				- метод максимального правдоподобия
					- вероятность vs правдоподобие
						- вероятность предсказывает неизвестные результаты по известным параметрам
						- правдоподобие оценивает неизвестные параметры по известным результатам
					- логарифмическая функция правдоподобия: L(X|teta) = ln fX(X|teta) = sum i=1..n (ln fX(xi|teta))
				- метод наименьших квадратов
				- метод моментов
			- виды статистических и эконометрических моделей
				- Линейная (OLS)
				- Авторегрессионная модель
				- Система одновременных уравнений (SEM)
				- Модель линейной вероятности (LPM)
				- Логит модель (Logit)
					- прогнозирует вероятность события по значениям множества признаков
					- путём подгонки данных к логистической кривой
					- дифур: dP/dt = tau P*(1-P/K)
						- P - популяция
						- t - время
						- K - ёмкость среды
					- логистическая кривая: P(t) = K P0 e^(tau*t) / (K + P0 (e^(tau*t) - 1))
					- сигмоида = логит-функция: 1 / (1+e^-z)
					- функция распределения - Бернулли: P{y|x} = p^y * (1-p)^(1-y), где параметр p = f(teta^T * x)
				- Пробит модель (Probit)
					- probit = probability unit
					- основана на нормальном распределении
					- частный случай модели бинарного выбора
					- probit-функция
						- обратна к интегральной функции (CDF) стандартного нормального распределения
						- определяет квантиль стандартного нормального распределения для заданной вероятности x q = Ф^−1(q)
					- пробит-модель: p(x) = P(Y=1|X=x) = Ф(x^T*b)
						- Ф - интегральная функция распределения (CDF) стандартного нормального распределения
						- b - неизвестные параметры, которые требуется оценить
					- оценка качества пробит-регрессии (или любой модели бинарного выбора)
						- статистика отношения правдоподобия LR
						- псевдо-коэффициент детерминации R2pseudo
						- коэффициент детерминации МакФаддена (индекс отношения правдоподобия) R2mcfadden, LRI 
						- информационные критерии Акаике, Шварца, Ханнана-Куинна AIC, BIC(SC), HQ
						- ...
		- кластерный анализ
	- линейная алгебра
		- матрицы и тензоры
		- matrix and tensor derivatives
			- https://www.coursera.org/learn/intro-to-deep-learning/lecture/YTunl/other-matrix-derivatives
			- https://compsci697l.github.io/docs/vecDerivs.pdf
			- https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
	- дискретная математика
		- разделы
			- теория функциональных систем
			- теория графов
			- теория автоматов
			- теория кодирования
			- комбинаторика
			- целочисленное программирование
		- курсы
			- coursera: Дискретная математика для компьютерных наук - Михаил Левин
	- численные методы
		- интерполирование и приближённое вычисление функций
			- интерполяция
			- равномерные приближения
			- среднеквадратичные приближения
		- численное дифференцирование и интегрирование
		- решение систем линейных уравнений
		- решение системы нелинейных уравнений
		- решение обыкновенных дифференциальных уравнений
		- решение уравнений в частных производных (уравнений математической физики)
		- оптимизации
			- оптимизация - нахождение экстремума целевой функции, ограниченной набором уравнений/неравенств
			- математическое программирование изучает теорию и методы решения задачи оптимизации
			- классификация
				- локальные/глобальные
				- детерминированные/случайные/комбинированные
				- размерность: одномерная, многомерная оптимизация
				- вид целевой функции: линейное, нелинейное, дискретное программирование
				- по гладкости и наличию частных производных: прямые методы, первого, второго порядка (про гессиан)
